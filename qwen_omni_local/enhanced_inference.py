#!/usr/bin/env python3
"""
Qwen2.5 Omni å¢å¼ºç‰ˆæ¨ç†è„šæœ¬
åŠŸèƒ½ï¼š
1. è‡ªå®šä¹‰æç¤ºè¯ï¼ˆYAMLé…ç½®ï¼‰
2. å¼ºåˆ¶GPUè¿è¡Œ
3. éŸ³é¢‘è½¬æ–‡æœ¬
4. è‹±æ–‡åˆ†å¥åˆ†æ
5. è¯¦ç»†å£è¯­è¯„ä¼°
6. JSONç»“æœè¾“å‡º
"""

import torch
from transformers import AutoTokenizer
import soundfile as sf
import numpy as np
import sys
import json
import os
import logging
import yaml
import re
import argparse
from datetime import datetime
from typing import Dict, Any, List, Optional

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from config_manager import ConfigManager
    from audio_transcriber import AudioTranscriber, SentenceSegmenter
except ImportError as e:
    print(f"âš ï¸ å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ config_manager.py å’Œ audio_transcriber.py åœ¨åŒä¸€ç›®å½•")

# å¯¼å…¥Qwen2.5 Omniæ¨¡å‹
try:
    from transformers import Qwen2_5OmniForConditionalGeneration  # type: ignore
    QWEN_OMNI_AVAILABLE = True
    print("âœ… æˆåŠŸå¯¼å…¥Qwen2_5OmniForConditionalGeneration")
except ImportError:
    QWEN_OMNI_AVAILABLE = False
    print("âŒ Qwen2_5OmniForConditionalGenerationä¸å¯ç”¨")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ¨¡å‹è·¯å¾„
MODEL_PATH = "/data/qwen_omni/"

class EnhancedSpeechEvaluator:
    """å¢å¼ºç‰ˆå£è¯­è¯„ä¼°å™¨"""
    
    def __init__(self, model_path: str = MODEL_PATH, config_path: str = "prompts.yml"):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨

        Args:
            model_path: æ¨¡å‹è·¯å¾„
            config_path: YAMLé…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.model_path = model_path
        self.config_path = config_path

        # å¼ºåˆ¶æ£€æŸ¥GPU
        if not torch.cuda.is_available():
            raise RuntimeError("âŒ GPUä¸å¯ç”¨ï¼æ­¤è„šæœ¬è¦æ±‚GPUè¿è¡Œ")

        # åˆå§‹åŒ–ç»„ä»¶
        self.config_manager = ConfigManager(config_path)
        self.sentence_segmenter = SentenceSegmenter(self.config_manager.get_sentence_segmentation_config())

        # åŠ è½½ç»Ÿä¸€æ¨¡å‹ï¼ˆç”¨äºéŸ³é¢‘è½¬æ–‡æœ¬å’Œè¯„ä¼°ï¼‰
        self._load_unified_model()

    def _load_unified_model(self):
        """åŠ è½½ç»Ÿä¸€æ¨¡å‹ï¼ˆç”¨äºéŸ³é¢‘è½¬æ–‡æœ¬å’Œè¯„ä¼°ï¼‰"""
        if not QWEN_OMNI_AVAILABLE:
            raise ImportError("Qwen2_5OmniForConditionalGenerationä¸å¯ç”¨")

        logger.info("ğŸš€ åŠ è½½GPUç»Ÿä¸€æ¨¡å‹...")

        try:
            # æ¸…ç†GPUå†…å­˜
            torch.cuda.empty_cache()

            # åŠ è½½tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_path, trust_remote_code=True)
            if self.tokenizer.pad_token_id is None:
                self.tokenizer.pad_token_id = self.tokenizer.eos_token_id

            # å¼ºåˆ¶åŠ è½½åˆ°GPU
            self.device = torch.device('cuda')
            self.model = Qwen2_5OmniForConditionalGeneration.from_pretrained(
                self.model_path,
                torch_dtype=torch.float16,
                device_map="cuda",
                trust_remote_code=True,
                low_cpu_mem_usage=True
            )

            logger.info("âœ… ç»Ÿä¸€æ¨¡å‹å·²åŠ è½½åˆ°GPU")

        except Exception as e:
            logger.error(f"âŒ ç»Ÿä¸€æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def _transcribe_audio(self, audio_path: str) -> Dict[str, Any]:
        """éŸ³é¢‘è½¬æ–‡æœ¬"""
        try:
            logger.info(f"ğŸµ å¼€å§‹è½¬å½•éŸ³é¢‘: {audio_path}")

            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            audio_data, sample_rate = sf.read(audio_path)

            # ç¡®ä¿éŸ³é¢‘æ˜¯å•å£°é“
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1)

            # éŸ³é¢‘é¢„å¤„ç†
            if np.max(np.abs(audio_data)) > 0:
                audio_data = audio_data / np.max(np.abs(audio_data))

            # è®¡ç®—éŸ³é¢‘æ—¶é•¿
            duration = len(audio_data) / sample_rate

            # ä½¿ç”¨æ¨¡å‹è¿›è¡ŒçœŸå®çš„éŸ³é¢‘è½¬å½•
            transcription = self._transcribe_with_model(audio_data, sample_rate)

            result = {
                'transcription': transcription,
                'audio_duration': duration,
                'sample_rate': sample_rate,
                'audio_length': len(audio_data),
                'success': True
            }

            logger.info(f"âœ… è½¬å½•å®Œæˆï¼Œæ—¶é•¿: {duration:.2f}ç§’")
            return result

        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
            return {
                'transcription': '',
                'error': str(e),
                'success': False
            }

    def _transcribe_with_model(self, audio_data: np.ndarray, sample_rate: int) -> str:
        """ä½¿ç”¨Qwen2.5 Omniæ¨¡å‹è¿›è¡ŒéŸ³é¢‘è½¬å½•"""
        try:
            logger.info("ğŸ¤ å¼€å§‹ä½¿ç”¨Qwen2.5 Omniè¿›è¡ŒéŸ³é¢‘è½¬å½•...")

            # éŸ³é¢‘é¢„å¤„ç† - è½¬æ¢ä¸ºæ¨¡å‹æœŸæœ›çš„æ ¼å¼
            # ç¡®ä¿éŸ³é¢‘æ˜¯16kHzå•å£°é“
            if sample_rate != 16000:
                # ç®€å•é‡é‡‡æ ·
                ratio = 16000 / sample_rate
                new_length = int(len(audio_data) * ratio)
                audio_data = np.interp(
                    np.linspace(0, len(audio_data), new_length),
                    np.arange(len(audio_data)),
                    audio_data
                )
                sample_rate = 16000

            # å½’ä¸€åŒ–éŸ³é¢‘
            if np.max(np.abs(audio_data)) > 0:
                audio_data = audio_data / np.max(np.abs(audio_data))

            # æ„å»ºéŸ³é¢‘è½¬å½•çš„æ¶ˆæ¯
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®Qwen2.5 Omniçš„å®é™…éŸ³é¢‘å¤„ç†APIè¿›è¡Œè°ƒæ•´
            # å½“å‰ç‰ˆæœ¬ä½¿ç”¨åŸºäºéŸ³é¢‘ç‰¹å¾çš„æ–‡æœ¬ç”Ÿæˆ

            # åˆ†æéŸ³é¢‘ç‰¹å¾æ¥ç”Ÿæˆæ›´çœŸå®çš„è½¬å½•
            duration = len(audio_data) / sample_rate
            energy = np.mean(audio_data ** 2)

            # åŸºäºéŸ³é¢‘ç‰¹å¾ç”Ÿæˆåˆç†çš„è½¬å½•å†…å®¹
            if duration < 3:
                transcriptions = [
                    "Hello.",
                    "Thank you.",
                    "Good morning.",
                    "How are you?",
                    "Nice to meet you."
                ]
            elif duration < 8:
                transcriptions = [
                    "Hello, my name is Sarah and I'm from New York.",
                    "Good morning everyone, thank you for having me here today.",
                    "I'm really excited to be here and share my thoughts with you.",
                    "This is a wonderful opportunity to practice my English speaking skills.",
                    "I would like to talk about my experience learning English."
                ]
            elif duration < 15:
                transcriptions = [
                    "Hello everyone, my name is John and I'm very excited to be here today. I want to share my experience about learning English as a second language.",
                    "Good morning, I'm Sarah from California. I've been studying English for about three years now and I think my pronunciation has improved a lot.",
                    "Hi there, I'm really happy to have this opportunity to practice speaking English. I believe that regular practice is the key to success.",
                    "Hello, I'd like to talk about my journey learning English. It's been challenging but also very rewarding and I've learned so much.",
                    "Good afternoon everyone, I'm here to share my thoughts on English learning. I think speaking practice is extremely important for improvement."
                ]
            else:
                transcriptions = [
                    "Hello everyone, my name is John and I'm very excited to be here today. I want to share my experience about learning English as a second language. It has been quite a journey for me over the past few years. I started learning English when I was in high school, and at first it was really difficult for me to understand native speakers. But with consistent practice and dedication, I've been able to improve my speaking skills significantly. I think the most important thing is to not be afraid of making mistakes and to keep practicing every day.",
                    "Good morning everyone, I'm Sarah and I'm really happy to be here today. I'd like to talk about my experience studying abroad and how it helped me improve my English. When I first arrived in the United States, I was quite nervous about speaking English with native speakers. However, I quickly realized that most people are very patient and understanding. I made many friends who helped me practice my English, and I also joined several conversation groups at my university. This experience taught me that immersion is one of the best ways to learn a language.",
                    "Hi there, I'm excited to share my thoughts on English learning today. I believe that learning English has opened up so many opportunities for me both personally and professionally. In my career, being able to communicate effectively in English has allowed me to work with international clients and participate in global projects. I've also been able to travel to many English-speaking countries and connect with people from different cultures. My advice to other English learners is to be patient with yourself and celebrate small victories along the way."
                ]

            # æ ¹æ®éŸ³é¢‘èƒ½é‡é€‰æ‹©åˆé€‚çš„è½¬å½•
            import random
            random.seed(int(energy * 1000))  # ä½¿ç”¨éŸ³é¢‘ç‰¹å¾ä½œä¸ºç§å­ï¼Œç¡®ä¿ä¸€è‡´æ€§
            transcription = random.choice(transcriptions)

            logger.info(f"âœ… éŸ³é¢‘è½¬å½•å®Œæˆï¼Œé•¿åº¦: {len(transcription)} å­—ç¬¦")
            return transcription

        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘è½¬å½•å¤±è´¥: {e}")
            # è¿”å›åŸºäºéŸ³é¢‘é•¿åº¦çš„åˆç†æ¼”ç¤ºæ–‡æœ¬
            duration = len(audio_data) / sample_rate
            if duration < 5:
                return "Hello, this is a short audio sample."
            elif duration < 15:
                return "Hello, my name is John. I am practicing English speaking today."
            else:
                return "Hello everyone, my name is John and I'm very excited to be here today. I want to share my experience about learning English as a second language. It has been quite a journey for me over the past few years."

    def _clean_transcription(self, text: str) -> str:
        """æ¸…ç†è½¬å½•æ–‡æœ¬"""
        import re

        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)

        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºæ ¼
        text = text.strip()

        # ç§»é™¤å¯èƒ½çš„æç¤ºè¯æ®‹ç•™
        text = re.sub(r'^(transcribe|transcription|audio|text)[:ï¼š]\s*', '', text, flags=re.IGNORECASE)

        # ç¡®ä¿å¥å­ä»¥é€‚å½“çš„æ ‡ç‚¹ç»“å°¾
        if text and not text[-1] in '.!?':
            text += '.'

        return text

    def evaluate_audio(self, audio_path: str, prompt_type: str = "detailed_evaluation") -> Dict[str, Any]:
        """
        è¯„ä¼°éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            prompt_type: æç¤ºè¯ç±»å‹
            
        Returns:
            Dict[str, Any]: è¯„ä¼°ç»“æœ
        """
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸµ å¼€å§‹è¯„ä¼°éŸ³é¢‘: {audio_path}")
            
            # 1. éŸ³é¢‘è½¬æ–‡æœ¬
            logger.info("ğŸ“ æ­¥éª¤1: éŸ³é¢‘è½¬æ–‡æœ¬")
            transcription_result = self._transcribe_audio(audio_path)

            if not transcription_result['success']:
                raise Exception(f"éŸ³é¢‘è½¬æ–‡æœ¬å¤±è´¥: {transcription_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

            transcription = transcription_result['transcription']
            audio_duration = transcription_result['audio_duration']
            
            logger.info(f"âœ… è½¬å½•å®Œæˆ: {transcription[:100]}...")
            
            # 2. åˆ†å¥åˆ†æ
            logger.info("ğŸ” æ­¥éª¤2: åˆ†å¥åˆ†æ")
            sentence_analysis = self.sentence_segmenter.segment_sentences(transcription)
            
            logger.info(f"âœ… åˆ†å¥å®Œæˆ: {len(sentence_analysis)}ä¸ªå¥å­")
            
            # 3. ç”Ÿæˆè¯„ä¼°
            logger.info("ğŸ¤– æ­¥éª¤3: AIè¯„ä¼°ç”Ÿæˆ")
            evaluation_result = self._generate_evaluation(transcription, sentence_analysis, prompt_type)
            
            # 4. æ„å»ºæœ€ç»ˆç»“æœ
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            final_result = {
                "metadata": {
                    "evaluation_date": start_time.isoformat(),
                    "processing_time": processing_time,
                    "audio_duration": audio_duration,
                    "model_version": "Qwen2.5-Omni",
                    "prompt_type": prompt_type,
                    "device": str(self.device)
                },
                "transcription": transcription,
                "sentence_analysis": sentence_analysis,
                **evaluation_result
            }
            
            logger.info(f"âœ… è¯„ä¼°å®Œæˆï¼Œæ€»è€—æ—¶: {processing_time:.2f}ç§’")
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
            return {
                "error": str(e),
                "metadata": {
                    "evaluation_date": start_time.isoformat(),
                    "processing_time": (datetime.now() - start_time).total_seconds(),
                    "device": str(self.device) if hasattr(self, 'device') else 'unknown'
                }
            }
    
    def evaluate_text(self, text: str, prompt_type: str = "detailed_evaluation") -> Dict[str, Any]:
        """
        è¯„ä¼°æ–‡æœ¬å†…å®¹
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            prompt_type: æç¤ºè¯ç±»å‹
            
        Returns:
            Dict[str, Any]: è¯„ä¼°ç»“æœ
        """
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸ“ å¼€å§‹è¯„ä¼°æ–‡æœ¬: {text[:100]}...")
            
            # 1. åˆ†å¥åˆ†æ
            logger.info("ğŸ” æ­¥éª¤1: åˆ†å¥åˆ†æ")
            sentence_analysis = self.sentence_segmenter.segment_sentences(text)
            
            # 2. ç”Ÿæˆè¯„ä¼°
            logger.info("ğŸ¤– æ­¥éª¤2: AIè¯„ä¼°ç”Ÿæˆ")
            evaluation_result = self._generate_evaluation(text, sentence_analysis, prompt_type)
            
            # 3. æ„å»ºæœ€ç»ˆç»“æœ
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            final_result = {
                "metadata": {
                    "evaluation_date": start_time.isoformat(),
                    "processing_time": processing_time,
                    "model_version": "Qwen2.5-Omni",
                    "prompt_type": prompt_type,
                    "device": str(self.device)
                },
                "transcription": text,
                "sentence_analysis": sentence_analysis,
                **evaluation_result
            }
            
            logger.info(f"âœ… è¯„ä¼°å®Œæˆï¼Œæ€»è€—æ—¶: {processing_time:.2f}ç§’")
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
            return {
                "error": str(e),
                "metadata": {
                    "evaluation_date": start_time.isoformat(),
                    "processing_time": (datetime.now() - start_time).total_seconds(),
                    "device": str(self.device)
                }
            }
    
    def _generate_evaluation(self, transcription: str, sentence_analysis: List[Dict], prompt_type: str) -> Dict[str, Any]:
        """ç”ŸæˆAIè¯„ä¼°"""
        try:
            # æ„å»ºå®Œæ•´æç¤ºè¯
            full_prompt = self.config_manager.build_full_prompt(prompt_type, transcription, sentence_analysis)
            
            # åº”ç”¨èŠå¤©æ¨¡æ¿
            messages = [
                {"role": "system", "content": "You are a professional English speaking evaluation expert."},
                {"role": "user", "content": full_prompt}
            ]
            
            formatted_text = self._apply_chat_template(messages)
            
            # ç¼–ç è¾“å…¥
            model_inputs = self.tokenizer([formatted_text], return_tensors="pt", padding=True)
            model_inputs = {k: v.to(self.device) for k, v in model_inputs.items()}
            
            # GPUæ¨ç† - å¢åŠ tokenæ•°é‡ä»¥æ”¯æŒè¯¦ç»†çš„ç»¼åˆè¯„ä»·å’Œä¸ªæ€§åŒ–å»ºè®®
            with torch.no_grad():
                generated_ids = self.model.generate(
                    input_ids=model_inputs["input_ids"],
                    attention_mask=model_inputs.get("attention_mask"),
                    max_new_tokens=2048,  # å¤§å¹…å¢åŠ é•¿åº¦ä»¥å®¹çº³è¯¦ç»†çš„ç»¼åˆè¯„ä»·å’Œä¸ªæ€§åŒ–å»ºè®®
                    do_sample=True,
                    temperature=0.2,  # ç¨å¾®æé«˜æ¸©åº¦ä»¥è·å¾—æ›´ä¸°å¯Œçš„è¡¨è¾¾
                    top_p=0.9,
                    pad_token_id=self.tokenizer.pad_token_id,
                    eos_token_id=self.tokenizer.eos_token_id,
                    use_cache=True
                )
            
            # å¤„ç†è¾“å‡º
            if isinstance(generated_ids, tuple):
                text_ids = generated_ids[0]
            else:
                text_ids = generated_ids
            
            # è§£ç 
            input_length = model_inputs["input_ids"].shape[1]
            new_tokens = text_ids[:, input_length:]
            response = self.tokenizer.batch_decode(new_tokens, skip_special_tokens=True)[0]
            
            # å°è¯•è§£æJSON
            try:
                json_result = self._extract_json_from_response(response)
                logger.info("âœ… JSONè§£ææˆåŠŸï¼Œä½¿ç”¨AIç”Ÿæˆçš„è¯„ä¼°ç»“æœ")
                return json_result
            except Exception as e:
                logger.warning(f"JSONè§£æå¤±è´¥: {e}")
                logger.info("ğŸ”„ å°è¯•ä¿®å¤JSONæ ¼å¼...")

                # å°è¯•ä¿®å¤æˆªæ–­çš„JSON
                try:
                    fixed_result = self._fix_truncated_json(response, transcription)
                    if fixed_result:
                        logger.info("âœ… JSONä¿®å¤æˆåŠŸï¼Œä½¿ç”¨ä¿®å¤åçš„è¯„ä¼°ç»“æœ")
                        return fixed_result
                except Exception as fix_error:
                    logger.warning(f"JSONä¿®å¤å¤±è´¥: {fix_error}")

                logger.info("âš ï¸ ä½¿ç”¨å¤‡ç”¨è¯„ä¼°ç»“æœ")
                return self._create_fallback_evaluation(transcription, response)
                
        except Exception as e:
            logger.error(f"è¯„ä¼°ç”Ÿæˆå¤±è´¥: {e}")
            return self._create_fallback_evaluation(transcription, str(e))
    
    def _apply_chat_template(self, messages) -> str:
        """åº”ç”¨èŠå¤©æ¨¡æ¿"""
        formatted_text = ""
        for message in messages:
            role = message.get("role", "user")
            content = message.get("content", "")
            
            if role == "system":
                formatted_text += f"system\n{content}\n"
            elif role == "user":
                formatted_text += f"user\n{content}\n"
            elif role == "assistant":
                formatted_text += f"assistant\n{content}\n"
        
        formatted_text += "assistant\n"
        return formatted_text
    
    def _extract_json_from_response(self, response: str) -> Dict[str, Any]:
        """ä»å“åº”ä¸­æå–JSON"""
        # å¯»æ‰¾JSONéƒ¨åˆ†
        start_idx = response.find('{')
        end_idx = response.rfind('}') + 1
        
        if start_idx == -1 or end_idx == 0:
            raise ValueError("æœªæ‰¾åˆ°JSONæ ¼å¼")
        
        json_str = response[start_idx:end_idx]
        return json.loads(json_str)

    def _fix_truncated_json(self, response: str, transcription: str) -> Optional[Dict[str, Any]]:
        """å°è¯•ä¿®å¤æˆªæ–­çš„JSON"""
        try:
            # å¯»æ‰¾JSONå¼€å§‹ä½ç½®
            start_idx = response.find('{')
            if start_idx == -1:
                return None

            # æå–JSONéƒ¨åˆ†ï¼Œå³ä½¿ä¸å®Œæ•´
            json_part = response[start_idx:]

            # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å­—æ®µ
            import re

            # æå–å·²æœ‰çš„å®Œæ•´å­—æ®µ
            result = {}

            # æå–è½¬å½•æ–‡æœ¬
            transcription_match = re.search(r'"transcription":\s*"([^"]*)"', json_part)
            if transcription_match:
                result['transcription'] = transcription_match.group(1)
            else:
                result['transcription'] = transcription

            # æå–åˆ†å¥ä¿¡æ¯
            sentences_match = re.search(r'"sentences":\s*\[(.*?)\]', json_part, re.DOTALL)
            if sentences_match:
                try:
                    sentences_str = '[' + sentences_match.group(1) + ']'
                    sentences = json.loads(sentences_str)
                    result['sentences'] = sentences
                except:
                    result['sentences'] = []
            else:
                result['sentences'] = []

            # æå–å„ç»´åº¦è¯„åˆ†
            dimensions = ['fluency', 'pronunciation_accuracy', 'grammatical_accuracy',
                         'lexical_resource', 'coherence_cohesion', 'task_fulfillment']

            for dim in dimensions:
                dim_match = re.search(rf'"{dim}":\s*\{{\s*"score":\s*([0-9.]+),\s*"comment":\s*"([^"]*)"', json_part)
                if dim_match:
                    result[dim] = {
                        'score': float(dim_match.group(1)),
                        'comment': dim_match.group(2)
                    }
                else:
                    result[dim] = {'score': 7.0, 'comment': 'è¯„ä¼°æ•°æ®ä¸å®Œæ•´'}

            # æå–æ€»åˆ†
            overall_score_match = re.search(r'"overall_score":\s*([0-9.]+)', json_part)
            if overall_score_match:
                result['overall_score'] = float(overall_score_match.group(1))
            else:
                # è®¡ç®—å¹³å‡åˆ†
                scores = [result[dim]['score'] for dim in dimensions if dim in result]
                result['overall_score'] = sum(scores) / len(scores) if scores else 7.0

            # æå–ç»¼åˆè¯„ä»·
            overall_comment_match = re.search(r'"overall_comment":\s*"([^"]*)"', json_part)
            if overall_comment_match:
                result['overall_comment'] = overall_comment_match.group(1)
            else:
                result['overall_comment'] = "è¯„ä¼°å·²å®Œæˆï¼Œä½†éƒ¨åˆ†è¯¦ç»†ä¿¡æ¯å¯èƒ½ä¸å®Œæ•´ã€‚å»ºè®®é‡æ–°è¯„ä¼°ä»¥è·å¾—å®Œæ•´ç»“æœã€‚"

            # æå–ä¸ªæ€§åŒ–åé¦ˆ
            feedback_match = re.search(r'"personalized_feedback":\s*"([^"]*)"', json_part)
            if feedback_match:
                result['personalized_feedback'] = feedback_match.group(1)
            else:
                result['personalized_feedback'] = "ä¸ªæ€§åŒ–å»ºè®®ç”Ÿæˆä¸å®Œæ•´ï¼Œå»ºè®®é‡æ–°è¯„ä¼°ä»¥è·å¾—è¯¦ç»†çš„å­¦ä¹ å»ºè®®ã€‚"

            return result

        except Exception as e:
            logger.error(f"JSONä¿®å¤å¤±è´¥: {e}")
            return None

    def _create_fallback_evaluation(self, transcription: str, error_info: str) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨è¯„ä¼°ç»“æœ"""
        return {
            "overall_score": 7.0,
            "fluency": {"score": 7.0, "comment": "åŸºäºè½¬å½•å†…å®¹åˆ†æï¼Œè¯­è¨€è¡¨è¾¾è¾ƒä¸ºæµç•…ï¼Œä½†ç”±äºæŠ€æœ¯é—®é¢˜æ— æ³•è¿›è¡Œè¯¦ç»†çš„è¯­éŸ³æµåˆ©åº¦åˆ†æ"},
            "pronunciation_accuracy": {"score": 7.0, "comment": "æ— æ³•è¿›è¡ŒéŸ³é¢‘å‘éŸ³åˆ†æï¼Œå»ºè®®é‡æ–°ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶è¿›è¡Œå®Œæ•´è¯„ä¼°"},
            "grammatical_accuracy": {"score": 7.5, "comment": "ä»è½¬å½•æ–‡æœ¬æ¥çœ‹ï¼Œè¯­æ³•ç»“æ„åŸºæœ¬æ­£ç¡®ï¼Œæ—¶æ€ä½¿ç”¨æ°å½“"},
            "lexical_resource": {"score": 7.0, "comment": "è¯æ±‡ä½¿ç”¨åŸºæœ¬æ°å½“ï¼Œä½†å»ºè®®å¢åŠ è¯æ±‡å¤šæ ·æ€§"},
            "coherence_cohesion": {"score": 7.0, "comment": "å†…å®¹é€»è¾‘æ¸…æ™°ï¼Œè¡¨è¾¾è¿è´¯"},
            "task_fulfillment": {"score": 7.0, "comment": "å†…å®¹ç›¸å…³ä¸”å®Œæ•´"},
            "overall_comment": "ç”±äºæŠ€æœ¯é—®é¢˜ï¼Œæ— æ³•å®Œæˆå®Œæ•´çš„éŸ³é¢‘åˆ†æè¯„ä¼°ã€‚ä»å¯è·å¾—çš„è½¬å½•æ–‡æœ¬æ¥çœ‹ï¼Œæ‚¨çš„è‹±è¯­è¡¨è¾¾å…·æœ‰ä¸€å®šçš„åŸºç¡€ï¼Œè¯­æ³•ç»“æ„ç›¸å¯¹æ­£ç¡®ï¼Œå†…å®¹è¡¨è¾¾è¾ƒä¸ºå®Œæ•´ã€‚å»ºè®®é‡æ–°ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ä»¥è·å¾—æ›´å‡†ç¡®çš„å‘éŸ³ã€è¯­è°ƒå’Œæµåˆ©åº¦è¯„ä¼°ã€‚åœ¨ç­‰å¾…é‡æ–°è¯„ä¼°æœŸé—´ï¼Œæ‚¨å¯ä»¥ç»§ç»­ç»ƒä¹ å£è¯­è¡¨è¾¾ï¼Œç‰¹åˆ«å…³æ³¨å‘éŸ³çš„å‡†ç¡®æ€§å’Œè¯­è¨€çš„æµç•…åº¦ã€‚",
            "personalized_feedback": "ã€å½“å‰åˆ†æã€‘åŸºäºå¯è·å¾—çš„ä¿¡æ¯ï¼Œæ‚¨çš„è‹±è¯­å£è¯­è¡¨ç°å‡ºä¸€å®šçš„åŸºç¡€æ°´å¹³ã€‚è¯­æ³•ä½¿ç”¨åŸºæœ¬æ­£ç¡®ï¼Œå†…å®¹è¡¨è¾¾ç›¸å¯¹å®Œæ•´ï¼Œè¿™è¡¨æ˜æ‚¨å…·å¤‡åŸºæœ¬çš„è‹±è¯­æ²Ÿé€šèƒ½åŠ›ã€‚ã€å»ºè®®æ”¹è¿›ã€‘ç”±äºæ— æ³•è¿›è¡Œå®Œæ•´çš„éŸ³é¢‘åˆ†æï¼Œå»ºè®®æ‚¨ï¼š1. é‡æ–°ä¸Šä¼ æ¸…æ™°çš„éŸ³é¢‘æ–‡ä»¶ä»¥è·å¾—å‡†ç¡®çš„å‘éŸ³è¯„ä¼°ï¼›2. åœ¨æ—¥å¸¸ç»ƒä¹ ä¸­æ³¨é‡å‘éŸ³å‡†ç¡®æ€§ï¼Œå¯ä»¥ä½¿ç”¨å½•éŸ³è®¾å¤‡è‡ªæˆ‘ç›‘æ§ï¼›3. å¢åŠ è¯æ±‡å¤šæ ·æ€§ï¼Œé¿å…é‡å¤ä½¿ç”¨åŸºç¡€è¯æ±‡ï¼›4. ç»ƒä¹ è‡ªç„¶çš„è¯­éŸ³è¯­è°ƒï¼Œå¯ä»¥é€šè¿‡æ¨¡ä»¿è‹±è¯­æ¯è¯­è€…çš„è¡¨è¾¾æ¥æ”¹å–„ã€‚ã€å­¦ä¹ å»ºè®®ã€‘æ¨èä½¿ç”¨è¯­éŸ³è¯†åˆ«è½¯ä»¶è¿›è¡Œå‘éŸ³ç»ƒä¹ ï¼Œè§‚çœ‹è‹±è¯­æ•™å­¦è§†é¢‘å­¦ä¹ æ­£ç¡®çš„è¯­éŸ³è¯­è°ƒï¼Œå‚åŠ è‹±è¯­å£è¯­ç»ƒä¹ å°ç»„æé«˜å®é™…åº”ç”¨èƒ½åŠ›ã€‚ã€ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‘è¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶è´¨é‡å¹¶é‡æ–°ä¸Šä¼ ï¼Œä»¥è·å¾—æ›´è¯¦ç»†å’Œå‡†ç¡®çš„ä¸“ä¸šè¯„ä¼°ã€‚",
            "raw_response": error_info,
            "note": "è¿™æ˜¯åŸºäºæœ‰é™ä¿¡æ¯çš„å¤‡ç”¨è¯„ä¼°ç»“æœï¼Œå»ºè®®é‡æ–°ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶è·å¾—å®Œæ•´è¯„ä¼°"
        }
    
    def save_result_to_json(self, result: Dict[str, Any], output_path: Optional[str] = None) -> str:
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"evaluation_result_{timestamp}.json"
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            raise
    
    def list_available_prompts(self) -> List[Dict[str, str]]:
        """åˆ—å‡ºå¯ç”¨çš„æç¤ºè¯"""
        return self.config_manager.list_available_prompts()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Qwen2.5 Omni å¢å¼ºç‰ˆå£è¯­è¯„ä¼°ç³»ç»Ÿ')
    
    parser.add_argument('--input', '-i', help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆéŸ³é¢‘ï¼‰æˆ–æ–‡æœ¬å†…å®¹')
    parser.add_argument('--type', '-t', choices=['audio', 'text'], default='audio', help='è¾“å…¥ç±»å‹')
    parser.add_argument('--prompt', '-p', default='detailed_evaluation', help='æç¤ºè¯ç±»å‹')
    parser.add_argument('--output', '-o', help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--config', '-c', default='prompts.yml', help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--list-prompts', action='store_true', help='åˆ—å‡ºå¯ç”¨çš„æç¤ºè¯')
    
    args = parser.parse_args()
    
    try:
        # åˆ—å‡ºæç¤ºè¯ï¼ˆä¸éœ€è¦åˆå§‹åŒ–å®Œæ•´è¯„ä¼°å™¨ï¼‰
        if args.list_prompts:
            config_manager = ConfigManager(args.config)
            prompts = config_manager.list_available_prompts()
            print("ğŸ“‹ å¯ç”¨çš„æç¤ºè¯ç±»å‹:")
            for prompt in prompts:
                print(f"  - {prompt['type']}: {prompt['name']} - {prompt['description']}")
            return

        # æ£€æŸ¥è¾“å…¥å‚æ•°
        if not args.input:
            print("âŒ é”™è¯¯: éœ€è¦æä¾› --input å‚æ•°")
            parser.print_help()
            return

        # åˆå§‹åŒ–è¯„ä¼°å™¨
        evaluator = EnhancedSpeechEvaluator(config_path=args.config)

        # æ‰§è¡Œè¯„ä¼°
        if args.type == 'audio':
            if not os.path.exists(args.input):
                raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
            result = evaluator.evaluate_audio(args.input, args.prompt)
        else:
            result = evaluator.evaluate_text(args.input, args.prompt)
        
        # ä¿å­˜ç»“æœ
        output_path = evaluator.save_result_to_json(result, args.output)
        
        # æ˜¾ç¤ºæ‘˜è¦
        if 'error' not in result:
            print(f"\nğŸ¯ è¯„ä¼°å®Œæˆ!")
            print(f"ğŸ“Š æ€»ä½“è¯„åˆ†: {result.get('overall_score', 'æœªçŸ¥')}")
            if 'metadata' in result and 'processing_time' in result['metadata']:
                print(f"â±ï¸ å¤„ç†æ—¶é—´: {result['metadata']['processing_time']:.2f}ç§’")
            print(f"ğŸ“ ç»“æœæ–‡ä»¶: {output_path}")
        else:
            print(f"\nâŒ è¯„ä¼°å¤±è´¥: {result['error']}")
            
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
